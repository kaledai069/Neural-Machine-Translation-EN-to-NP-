{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "542b0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x16115c03150>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import re\n",
    "import unicodedata\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001b0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'MAX_VOCAB_SIZE': 13000,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'raw_dataset_path': './dataset/por.txt',\n",
    "    'MAX_SEQ_LEN': 16,\n",
    "    'BUFFER_SIZE': 1000,\n",
    "    'UNITS': 256,\n",
    "    'EPOCHS': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffd6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "dataset_path = pathlib.Path(config['raw_dataset_path'])\n",
    "text_data = dataset_path.read_text(encoding = 'utf-8')\n",
    "\n",
    "lines = text_data.splitlines()\n",
    "pairs = [line.split('\\t') for line in lines][:1200]\n",
    "\n",
    "context_en = np.array([context for context, target, _ in pairs])\n",
    "target_por = np.array([target for context, target, _ in pairs])\n",
    "\n",
    "sentences = np.array((context_en, target_por))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12512c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['go', 'on', '.'], ['siga', 'em', 'frente', '.'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^ a-z.?!,¿]\", \"\", text)\n",
    "    text = re.sub(r\"([.?!,¿])\", r\" \\1 \", text)\n",
    "    text = text.strip()\n",
    "    return text.split()\n",
    "\n",
    "tokenizer(context_en[34]), tokenizer(target_por[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "95d3e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold, max_vocab_size):\n",
    "        # maintain two different mappings\n",
    "        self.itos = {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: '[UNK]'}\n",
    "        self.stoi = {'[PAD]': 0, '[SOS]': 1, '[EOS]': 2, '[UNK]': 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        self.pad_id = self.stoi['[PAD]']\n",
    "        self.sos_id = self.stoi['[SOS]']\n",
    "        self.eos_id = self.stoi['[EOS]']\n",
    "        self.oov_id = self.stoi['[UNK]']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.stoi\n",
    "\n",
    "    def token_to_ids(self, tokens):\n",
    "        if isinstance(tokens, str): # handle a single word or sentence here\n",
    "            token_list = self.tokenizer(tokens)\n",
    "            return [self.stoi[t] if t in self.stoi else self.stoi['[UNK]'] for t in token_list]\n",
    "\n",
    "        elif isinstance(tokens, list):\n",
    "            return [self.stoi[t] if t in self.stoi else self.stoi['[UNK]'] for t in tokens]\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"Input must be either String or List of words.\")\n",
    "\n",
    "    def ids_to_token(self, ids):\n",
    "        return [self.itos[id] if id in self.itos else self.itos[3] for id in ids]\n",
    "\n",
    "    # building vocab with the input sentence list\n",
    "    def adapt(self, sentences, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        idx = len(self.itos)\n",
    "        token_freqs = {}\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for token in self.tokenizer(sentence):\n",
    "                if token not in self.stoi:\n",
    "                    token_freqs[token] = 1\n",
    "                else:\n",
    "                    token_freqs[token] += 1\n",
    "                \n",
    "                if (token_freqs[token] == self.freq_threshold) and (idx < self.max_vocab_size):\n",
    "                    self.itos[idx] = token\n",
    "                    self.stoi[token] = idx\n",
    "                    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1a7e967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 800)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english vocabulary\n",
    "en_vocab = Vocabulary(freq_threshold = 1, max_vocab_size = config['MAX_VOCAB_SIZE'])\n",
    "en_vocab.adapt(context_en, tokenizer)\n",
    "\n",
    "# portuguese vocabulary\n",
    "por_vocab = Vocabulary(freq_threshold = 1, max_vocab_size = config['MAX_VOCAB_SIZE'])\n",
    "por_vocab.adapt(target_por, tokenizer)\n",
    "\n",
    "en_vocab.vocab_size(), por_vocab.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8c2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here I am. ---------> Aqui estou.\n",
      "\n",
      "Encoder Input IDs: \n",
      "[1, 194, 20, 62, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Pre-Attention Decoder Input IDs (Shifted to the Right): \n",
      "[1, 402, 47, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Post-Attention Decoder Input IDs: \n",
      "[402, 47, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_idx = 789\n",
    "en_translation = context_en[test_idx]\n",
    "por_translation = target_por[test_idx]\n",
    "\n",
    "print(en_translation, '--------->', por_translation)\n",
    "\n",
    "max_seq_len = 16\n",
    "context_tokens = en_vocab.token_to_ids(en_translation)\n",
    "target_tokens = por_vocab.token_to_ids(por_translation)\n",
    "\n",
    "print(\"\\nEncoder Input IDs: \")\n",
    "print([en_vocab.sos_id] + context_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 2) * [en_vocab.pad_id])\n",
    "print(\"\\nPre-Attention Decoder Input IDs (Shifted to the Right): \")\n",
    "print([en_vocab.sos_id] + target_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 2) * [en_vocab.pad_id])\n",
    "print(\"\\nPost-Attention Decoder Input IDs: \")\n",
    "print(target_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 1) * [en_vocab.pad_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84839390",
   "metadata": {},
   "source": [
    "### Neural Machine Translation Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feee94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_dataset(Dataset):\n",
    "    def __init__(self, translation_pairs, tokenizer, vocabularies, max_seq_len, device = 'cpu'):\n",
    "        print(translation_pairs.shape)\n",
    "        self.translation_pairs = translation_pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.en_vocab, self.por_vocab = vocabularies\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device\n",
    "\n",
    "        # for convenience \n",
    "        self.sos_id = self.en_vocab.sos_id\n",
    "        self.eos_id = self.en_vocab.eos_id\n",
    "        self.pad_id = self.en_vocab.pad_id\n",
    "        self.oov_id = self.en_vocab.oov_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.translation_pairs.shape[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        req_pair = self.translation_pairs[:, idx]\n",
    "        en_translation, por_translation = req_pair\n",
    "\n",
    "        context_tokens = self.en_vocab.token_to_ids(en_translation)\n",
    "        target_tokens = self.por_vocab.token_to_ids(por_translation)\n",
    "\n",
    "        # encoder input tokens\n",
    "        encoder_input = (\n",
    "            [self.sos_id] + \n",
    "            context_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(context_tokens) - 2) * [self.pad_id]\n",
    "            )\n",
    "        \n",
    "        # pre-attention decoder input tokens\n",
    "        pre_decoder_input = (\n",
    "            [self.sos_id] + \n",
    "            target_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(target_tokens) - 2) * [self.pad_id] \n",
    "        )\n",
    "\n",
    "        # post-attention decoder output tokens\n",
    "        post_decoder_output = (\n",
    "            target_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(target_tokens) - 1) * [self.pad_id]\n",
    "        )\n",
    "\n",
    "        encoder_input_tensor = torch.tensor(encoder_input[:max_seq_len], dtype = torch.long).to(self.device)\n",
    "        pre_decoder_input_tensor = torch.tensor(pre_decoder_input[:max_seq_len], dtype = torch.long).to(self.device)\n",
    "        post_decoder_output_tensor = torch.tensor(post_decoder_output[:max_seq_len], dtype = torch.long).to(self.device)\n",
    "\n",
    "        return encoder_input_tensor, pre_decoder_input_tensor, post_decoder_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a66997a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1002), (2, 198))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and val_dataset\n",
    "is_train = np.random.uniform(size = (sentences.shape[-1],)) < 0.85\n",
    "train_raw_set = sentences[:, is_train]\n",
    "val_raw_set = sentences[:, ~is_train]\n",
    "\n",
    "train_raw_set.shape, val_raw_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974817a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1002)\n",
      "(2, 198)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NMT_dataset(train_raw_set, tokenizer, (en_vocab, por_vocab), config['MAX_SEQ_LEN'])\n",
    "val_dataset = NMT_dataset(val_raw_set, tokenizer, (en_vocab, por_vocab), config['MAX_SEQ_LEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a832fb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 1002/1002 [00:00<00:00, 11207.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'encoder_in': 16, 'target_in': 16, 'target_out': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_dict = {\n",
    "    'encoder_in': 0, \n",
    "    'target_in': 0, \n",
    "    'target_out': 0\n",
    "}\n",
    "context_target_token_lengths = {\n",
    "    'encoder_in': [], \n",
    "    'target_in': [], \n",
    "    'target_out': []\n",
    "}\n",
    "\n",
    "for data in tqdm(train_dataset, ncols = 100):\n",
    "    encoder_in, target_in, target_out = data\n",
    "    context_target_token_lengths['encoder_in'].append(len(encoder_in))\n",
    "    context_target_token_lengths['target_in'].append(len(target_in))\n",
    "    context_target_token_lengths['target_out'].append(len(target_out))\n",
    "    \n",
    "    if len(encoder_in) > max_len_dict['encoder_in']:\n",
    "        max_len_dict['encoder_in'] = len(encoder_in)\n",
    "        \n",
    "    if len(target_in) > max_len_dict['target_in']:\n",
    "        max_len_dict['target_in'] = len(target_in)\n",
    "        \n",
    "    if len(target_out) > max_len_dict['target_out']:\n",
    "        max_len_dict['target_out'] = len(target_out)\n",
    "\n",
    "max_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf2dfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(16, 1002)], [(16, 1002)], [(16, 1002)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(context_target_token_lengths['encoder_in']).most_common(1), Counter(context_target_token_lengths['target_in']).most_common(1), Counter(context_target_token_lengths['target_out']).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0aa50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # pad sequences according to the maximum len in a batch, and then standardize all the batch inputs to same length\n",
    "    contexts, target_ins, target_outs = zip(*batch)\n",
    "    max_len = max([len(x) for x in contexts])\n",
    "\n",
    "    # padding sequences\n",
    "    padded_contexts = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in contexts]\n",
    "    padded_target_ins = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in target_ins]\n",
    "    padded_target_outs = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in target_outs]\n",
    "\n",
    "    padded_contexts = torch.stack(padded_contexts)\n",
    "    padded_target_ins = torch.stack(padded_target_ins)\n",
    "    padded_target_outs = torch.stack(padded_target_outs)\n",
    "\n",
    "    return padded_contexts, padded_target_ins, padded_target_outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342a41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = config['BATCH_SIZE'], \n",
    "    shuffle = True,\n",
    "#     collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size = config['BATCH_SIZE'], \n",
    "    shuffle = False,\n",
    "#     collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118950b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) * config['BATCH_SIZE'], len(val_loader) * config['BATCH_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c36198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 256])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # input embedding\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = vocab_size,\n",
    "            embedding_dim = units,\n",
    "            padding_idx = 0 \n",
    "        )\n",
    "        \n",
    "        # bi-directional LSTM\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = units,\n",
    "            hidden_size = units,\n",
    "            batch_first = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        x = self.embedding(context)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x[:, :, :self.rnn.hidden_size] + x[:, :, self.rnn.hidden_size:]\n",
    "\n",
    "        return x\n",
    "    \n",
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "\n",
    "encoder = Encoder(vocab_size, units)\n",
    "\n",
    "input_tensor = next(iter(train_dataset))\n",
    "input_tensor = input_tensor[0].unsqueeze(0)\n",
    "output = encoder(input_tensor)\n",
    "print(output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f249a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 256])\n"
     ]
    }
   ],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, units):\n",
    "\n",
    "        super(CrossAttention, self).__init__()\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim = units,  # the size of Q, K, V dims is the embedding dimension\n",
    "            num_heads = 1,  \n",
    "            batch_first = True  # (batch_size, sequence_length, embedding_dim) either (seq_len, batch_size, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(units)\n",
    "        \n",
    "        # to accumulate the inputs from encoder output (encoder_in) and the pre-attention decoder (target_in)\n",
    "        self.add = nn.ModuleList([nn.Linear(units, units) for _ in range(2)])\n",
    "\n",
    "    def forward(self, context, target):\n",
    "        # query is the target_in from the pre-attention decoder, while key/value are the context from the encoded context from the encoder\n",
    "        attn_output, _ = self.multihead_attn(query = target, key = context, value = context)\n",
    "        \n",
    "        x = self.add[0](target) + self.add[1](attn_output)\n",
    "        return self.layernorm(x)\n",
    "\n",
    "\n",
    "units = config['UNITS']\n",
    "\n",
    "cross_attention = CrossAttention(units)\n",
    "context_tensor = torch.randn(8, 16, units)  \n",
    "target_tensor = torch.randn(8, 16, units)    \n",
    "output = cross_attention(context_tensor, target_tensor)\n",
    "print(output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b94864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 13000])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, units, padding_idx = 0)\n",
    "        self.pre_attention_rnn = nn.LSTM(units, units, batch_first = True)\n",
    "        self.attention = CrossAttention(units)\n",
    "        self.post_attention_rnn = nn.LSTM(units, units, batch_first = True)\n",
    "        self.output_layer = nn.Linear(units, vocab_size)\n",
    "\n",
    "    def forward(self, context, target, state = None, return_state = False):\n",
    "        \n",
    "        x = self.embedding(target)\n",
    "        \n",
    "        # pre-attention-LSTM (decoder)\n",
    "        if state is None:\n",
    "            x, (hidden_state, cell_state) = self.pre_attention_rnn(x)\n",
    "        else:\n",
    "            x, (hidden_state, cell_state) = self.pre_attention_rnn(x, state)\n",
    "        \n",
    "        # cross-attention between pre-attention-LSTM output and the encoded context\n",
    "        x = self.attention(context, x)\n",
    "        \n",
    "        # post-attention-LSTM (decoder)\n",
    "        x, _ = self.post_attention_rnn(x)\n",
    "\n",
    "        # last linear (dense) layer\n",
    "        logits = self.output_layer(x)\n",
    "        logits = F.log_softmax(logits, dim = -1)\n",
    "\n",
    "        if return_state:\n",
    "            return logits, (hidden_state, cell_state)\n",
    "\n",
    "        return logits\n",
    "\n",
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "decoder = Decoder(vocab_size, units)\n",
    "\n",
    "context_tensor = torch.randn(8, 15, units)  \n",
    "target_tensor = torch.randint(0, vocab_size, (8, 16)).long() \n",
    "\n",
    "output = decoder(context_tensor, target_tensor)\n",
    "print(output.shape) # (batch_size, max_seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aa69111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_Translator(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(NMT_Translator, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size, units)\n",
    "        self.decoder = Decoder(vocab_size, units)\n",
    "        \n",
    "    def forward(self, context, target):\n",
    "        encoded_context = self.encoder(context)\n",
    "        logits = self.decoder(encoded_context, target) # this target here is the target_in (target_out is used for training)\n",
    "        \n",
    "        return logits # (batch_size, max_seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea725999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 15]) torch.Size([8, 16])\n",
      "torch.Size([8, 16, 13000])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "\n",
    "translator = NMT_Translator(vocab_size, units)\n",
    "\n",
    "context_tensor = torch.randint(0, vocab_size, (8, 15)).long()  # (batch_size, seq_len, units)\n",
    "target_tensor = torch.randint(0, vocab_size, (8, 16)).long()  # (batch_size, seq_len)\n",
    "print(context_tensor.shape, target_tensor.shape)\n",
    "\n",
    "\n",
    "output = translator(context_tensor, target_tensor)\n",
    "print(output.shape)  # (batch_size, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8350f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAcc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedAcc, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.argmax(dim = -1)\n",
    "\n",
    "        mask = (y_true != 0).float()\n",
    "        correct = (y_true == y_pred).float() * mask\n",
    "        return correct.sum() / mask.sum()\n",
    "    \n",
    "class SparseCategoricalMaskedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseCategoricalMaskedLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        batch_size, seq_len, vocab_size = y_pred.shape\n",
    "    \n",
    "        # mask to avoid the padding sequence\n",
    "        # for loss mask\n",
    "        mask = (y_true != 0).float()\n",
    "\n",
    "        y_pred = y_pred.view(-1, y_pred.size(-1))\n",
    "        y_true = y_true.view(-1)\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, y_true.long(), reduction='none')\n",
    "\n",
    "        loss = loss.view(batch_size, seq_len)\n",
    "        loss *= mask\n",
    "\n",
    "        return loss.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c6b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "model = NMT_Translator(vocab_size, units)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "masked_loss_fn = MaskedLoss()\n",
    "masked_acc_fn = MaskedAcc()\n",
    "\n",
    "sparse_masked_loss_fn = SparseCategoricalMaskedLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9783990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 4.3761, accuracy: 0.4669\n",
      "Validation loss: 3.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 2.9841, accuracy: 0.5087\n",
      "Validation loss: 3.3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 2.6018, accuracy: 0.5450\n",
      "Validation loss: 3.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 2.3407, accuracy: 0.5679\n",
      "Validation loss: 3.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 2.1225, accuracy: 0.5872\n",
      "Validation loss: 3.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 1.9355, accuracy: 0.6114\n",
      "Validation loss: 3.1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 1.7610, accuracy: 0.6262\n",
      "Validation loss: 2.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 1.5568, accuracy: 0.6572\n",
      "Validation loss: 2.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 1.3914, accuracy: 0.6735\n",
      "Validation loss: 2.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 1.2401, accuracy: 0.6970\n",
      "Validation loss: 2.9446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parzi\\AppData\\Local\\Temp\\ipykernel_6252\\1716338257.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(config['EPOCHS']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['EPOCHS']}\", leave = False)\n",
    "    for batch in train_loader_tqdm:\n",
    "        \n",
    "        # encoder input, pre-attention-decoder input and post-attention-decoder target output\n",
    "        context, target_in, target_out = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(context, target_in)\n",
    "\n",
    "        loss = sparse_masked_loss_fn(output.float(), target_out.float())\n",
    "        acc = masked_acc_fn(output.float(), target_out.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item()\n",
    "        train_loader_tqdm.set_postfix(loss = loss.item(), accuracy = acc.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{config['EPOCHS']}\")\n",
    "    print(f\"Training loss: {avg_loss:.4f}, accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            context, target_in, target_out = batch\n",
    "            output = model(context, target_in)\n",
    "            loss = sparse_masked_loss_fn(output.float(), target_out.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0dcae",
   "metadata": {},
   "source": [
    "#### Next Token Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "20c76397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(decoder, context, next_token, done, state, eos_id, temperature=0.0):\n",
    "    \n",
    "    logits, state = decoder(context, next_token, state = state, return_state = True)\n",
    "    \n",
    "    # Shape: [batch_size, vocab_size]\n",
    "    logits = logits.squeeze(0)    \n",
    "    \n",
    "    if temperature == 0.0:\n",
    "        next_token = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "    else:\n",
    "        logits = logits / temperature\n",
    "        next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
    "    \n",
    "\n",
    "    logits = logits.squeeze()\n",
    "    next_token = next_token.squeeze()\n",
    "    \n",
    "    logit = logits[next_token].item()  \n",
    "    \n",
    "    \n",
    "    next_token = next_token.view(1, 1)\n",
    "    \n",
    "    if next_token.item() == eos_id:\n",
    "        done = True\n",
    "    \n",
    "    return next_token, logit, state, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2b211d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './best_model.pth'\n",
    "\n",
    "inf_model = NMT_Translator(vocab_size, units)\n",
    "inf_model.load_state_dict(torch.load(model_path, weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1335817c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salve o [UNK] ele o [UNK] o [UNK] tom meu e uma [UNK] o [UNK] e'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(model, context, context_tokenizer, sos_id = 1, eos_id = 2, max_gen_len = 16, temp = 0.7):\n",
    "    \n",
    "    tokens, logits = [], []\n",
    "\n",
    "    context = context_tokenizer(test_en_sentence)\n",
    "    context = torch.tensor(en_vocab.token_to_ids(context), dtype = torch.long).to('cpu')\n",
    "    context = model.encoder(context.unsqueeze(0))\n",
    "\n",
    "    next_token = torch.tensor([[sos_id]], dtype=torch.long)\n",
    "\n",
    "    state = [\n",
    "        torch.zeros((1, 1, config['UNITS']), dtype=torch.float),\n",
    "        torch.zeros((1, 1, config['UNITS']), dtype=torch.float)\n",
    "        ]\n",
    "\n",
    "    done = False\n",
    "\n",
    "    for i in range(max_gen_len):\n",
    "        next_token, logit, state, done = generate_next_token(\n",
    "                decoder = model.decoder,\n",
    "                context = context,\n",
    "                next_token = next_token,\n",
    "                done = done,\n",
    "                state = state,\n",
    "                eos_id = eos_id,\n",
    "                temperature = temp\n",
    "            )\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "        tokens.append(next_token)\n",
    "\n",
    "        logits.append(logit)\n",
    "\n",
    "    tokens = torch.cat(tokens, dim=-1)\n",
    "    return \" \".join(por_vocab.ids_to_token(tokens.squeeze().tolist()))\n",
    "\n",
    "temp = 0.7\n",
    "test_en_sentence = 'Hello, there'\n",
    "sos_id = 1\n",
    "eos_id = 2\n",
    "max_gen_len = 16\n",
    "\n",
    "translate(inf_model, test_en_sentence, tokenizer, sos_id, eos_id, max_gen_len, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8c893137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 51.54486831107658\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "\n",
    "candidates = [\n",
    "    \"The cat is on the mat.\",\n",
    "    \"There is a cat on the mat.\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [\"The cat is sitting on the mat.\"],\n",
    "    [\"There is a cat on the mat.\"]\n",
    "]\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(candidates, references)\n",
    "\n",
    "print(f\"BLEU score: {bleu.score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
