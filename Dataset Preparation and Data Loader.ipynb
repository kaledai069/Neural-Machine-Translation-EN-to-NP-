{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "542b0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x28e18da72d0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import re\n",
    "import unicodedata\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a5eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'MAX_VOCAB_SIZE': 13000,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'raw_dataset_path': './dataset/por.txt',\n",
    "    'MAX_SEQ_LEN': 16,\n",
    "    'BUFFER_SIZE': 1000,\n",
    "    'UNITS': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffd6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "dataset_path = pathlib.Path(config['raw_dataset_path'])\n",
    "text_data = dataset_path.read_text(encoding = 'utf-8')\n",
    "\n",
    "lines = text_data.splitlines()\n",
    "pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "context_en = np.array([context for context, target, _ in pairs])\n",
    "target_por = np.array([target for context, target, _ in pairs])\n",
    "\n",
    "sentences = np.array((context_en, target_por))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12512c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['go', 'on', '.'], ['siga', 'em', 'frente', '.'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^ a-z.?!,¿]\", \"\", text)\n",
    "    text = re.sub(r\"([.?!,¿])\", r\" \\1 \", text)\n",
    "    text = text.strip()\n",
    "    return text.split()\n",
    "\n",
    "tokenizer(context_en[34]), tokenizer(target_por[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d3e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold, max_vocab_size):\n",
    "        # maintain two different mappings\n",
    "        self.itos = {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: '[UNK]'}\n",
    "        self.stoi = {'[PAD]': 0, '[SOS]': 1, '[EOS]': 2, '[UNK]': 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        self.pad_id = self.stoi['[PAD]']\n",
    "        self.sos_id = self.stoi['[SOS]']\n",
    "        self.eos_id = self.stoi['[EOS]']\n",
    "        self.oov_id = self.stoi['[UNK]']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.stoi\n",
    "\n",
    "    def token_to_ids(self, tokens):\n",
    "        if isinstance(tokens, str): # handle a single word or sentence here\n",
    "            token_list = self.tokenizer(tokens)\n",
    "            return [self.stoi[t] if t in self.stoi else self.stoi['[UNK]'] for t in token_list]\n",
    "\n",
    "        elif isinstance(tokens, list):\n",
    "            return [self.stoi[t] if t in self.stoi else self.stoi['[UNK]'] for t in tokens]\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"Input must be either String or List of words.\")\n",
    "\n",
    "    def ids_to_token(self, ids):\n",
    "        return [self.itos[id] for id in ids]\n",
    "\n",
    "    # building vocab with the input sentence list\n",
    "    def adapt(self, sentences, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        idx = len(self.itos)\n",
    "        token_freqs = {}\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for token in self.tokenizer(sentence):\n",
    "                if token not in self.stoi:\n",
    "                    token_freqs[token] = 1\n",
    "                else:\n",
    "                    token_freqs[token] += 1\n",
    "                \n",
    "                if (token_freqs[token] == self.freq_threshold) and (idx < self.max_vocab_size):\n",
    "                    self.itos[idx] = token\n",
    "                    self.stoi[token] = idx\n",
    "                    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7e967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 13000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english vocabulary\n",
    "en_vocab = Vocabulary(freq_threshold = 1, max_vocab_size = config['MAX_VOCAB_SIZE'])\n",
    "en_vocab.adapt(context_en, tokenizer)\n",
    "\n",
    "# portuguese vocabulary\n",
    "por_vocab = Vocabulary(freq_threshold = 1, max_vocab_size = config['MAX_VOCAB_SIZE'])\n",
    "por_vocab.adapt(target_por, tokenizer)\n",
    "\n",
    "en_vocab.vocab_size(), por_vocab.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8c2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here I am. ---------> Aqui estou.\n",
      "\n",
      "Encoder Input IDs: \n",
      "[1, 194, 20, 62, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Pre-Attention Decoder Input IDs (Shifted to the Right): \n",
      "[1, 402, 47, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Post-Attention Decoder Input IDs: \n",
      "[402, 47, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_idx = 789\n",
    "en_translation = context_en[test_idx]\n",
    "por_translation = target_por[test_idx]\n",
    "\n",
    "print(en_translation, '--------->', por_translation)\n",
    "\n",
    "max_seq_len = 16\n",
    "context_tokens = en_vocab.token_to_ids(en_translation)\n",
    "target_tokens = por_vocab.token_to_ids(por_translation)\n",
    "\n",
    "print(\"\\nEncoder Input IDs: \")\n",
    "print([en_vocab.sos_id] + context_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 2) * [en_vocab.pad_id])\n",
    "print(\"\\nPre-Attention Decoder Input IDs (Shifted to the Right): \")\n",
    "print([en_vocab.sos_id] + target_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 2) * [en_vocab.pad_id])\n",
    "print(\"\\nPost-Attention Decoder Input IDs: \")\n",
    "print(target_tokens + [en_vocab.eos_id] + (max_seq_len - len(context_tokens) - 1) * [en_vocab.pad_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7101f97",
   "metadata": {},
   "source": [
    "### Neural Machine Translation Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cea0c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_dataset(Dataset):\n",
    "    def __init__(self, translation_pairs, tokenizer, vocabularies, max_seq_len):\n",
    "        print(translation_pairs.shape)\n",
    "        self.translation_pairs = translation_pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.en_vocab, self.por_vocab = vocabularies\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # for convenience \n",
    "        self.sos_id = self.en_vocab.sos_id\n",
    "        self.eos_id = self.en_vocab.eos_id\n",
    "        self.pad_id = self.en_vocab.pad_id\n",
    "        self.oov_id = self.en_vocab.oov_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.translation_pairs.shape[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        req_pair = self.translation_pairs[:, idx]\n",
    "        en_translation, por_translation = req_pair\n",
    "\n",
    "        context_tokens = self.en_vocab.token_to_ids(en_translation)\n",
    "        target_tokens = self.por_vocab.token_to_ids(por_translation)\n",
    "\n",
    "        # encoder input tokens\n",
    "        encoder_input = (\n",
    "            [self.sos_id] + \n",
    "            context_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(context_tokens) - 2) * [self.pad_id]\n",
    "            )\n",
    "        \n",
    "        # pre-attention decoder input tokens\n",
    "        pre_decoder_input = (\n",
    "            [self.sos_id] + \n",
    "            target_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(target_tokens) - 2) * [self.pad_id] \n",
    "        )\n",
    "\n",
    "        # post-attention decoder output tokens\n",
    "        post_decoder_output = (\n",
    "            target_tokens + \n",
    "            [self.eos_id] + \n",
    "            (self.max_seq_len - len(target_tokens) - 1) * [self.pad_id]\n",
    "        )\n",
    "\n",
    "        encoder_input_tensor = torch.tensor(encoder_input, dtype = torch.long)\n",
    "        pre_decoder_input_tensor = torch.tensor(pre_decoder_input, dtype = torch.long)\n",
    "        post_decoder_output_tensor = torch.tensor(post_decoder_output, dtype = torch.long)\n",
    "\n",
    "        return encoder_input_tensor, pre_decoder_input_tensor, post_decoder_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a66997a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 161909), (2, 28730))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and val_dataset\n",
    "is_train = np.random.uniform(size = (sentences.shape[-1],)) < 0.85\n",
    "train_raw_set = sentences[:, is_train]\n",
    "val_raw_set = sentences[:, ~is_train]\n",
    "\n",
    "train_raw_set.shape, val_raw_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efc0d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 161909)\n",
      "(2, 28730)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NMT_dataset(train_raw_set, tokenizer, (en_vocab, por_vocab), config['MAX_SEQ_LEN'])\n",
    "val_dataset = NMT_dataset(val_raw_set, tokenizer, (en_vocab, por_vocab), config['MAX_SEQ_LEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32f2f9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 4, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 6, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([6, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "da4bbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unpack the batch (you might need to adjust this if your data is structured differently)\n",
    "    contexts, target_ins, target_outs = zip(*batch)\n",
    "\n",
    "    # Find the max length in the batch\n",
    "    max_len = max([len(x) for x in contexts])\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_contexts = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in contexts]\n",
    "    padded_target_ins = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in target_ins]\n",
    "    padded_target_outs = [torch.nn.functional.pad(x, (0, max_len - len(x))) for x in target_outs]\n",
    "\n",
    "    # Stack the tensors to form a batch\n",
    "    padded_contexts = torch.stack(padded_contexts)\n",
    "    padded_target_ins = torch.stack(padded_target_ins)\n",
    "    padded_target_outs = torch.stack(padded_target_outs)\n",
    "\n",
    "    return padded_contexts, padded_target_ins, padded_target_outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dae3b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = config['BATCH_SIZE'], \n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size = config['BATCH_SIZE'], \n",
    "    shuffle = False,\n",
    "    collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d4350f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161912, 28736)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) * config['BATCH_SIZE'], len(val_loader) * config['BATCH_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "54703a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = vocab_size,\n",
    "            embedding_dim = units,\n",
    "            padding_idx = 0  # Assuming padding index is 0, similar to mask_zero in Keras\n",
    "        )\n",
    "        \n",
    "        # bi-directional LSTM\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = units,\n",
    "            hidden_size = units,\n",
    "            batch_first = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (torch.Tensor): The sentence to translate\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded sentence to translate\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass the context through the embedding layer\n",
    "        x = self.embedding(context)\n",
    "\n",
    "        # Pass the output of the embedding through the RNN\n",
    "        x, _ = self.rnn(x)\n",
    "\n",
    "        # Merge the bidirectional outputs by summing them\n",
    "        x = x[:, :, :self.rnn.hidden_size] + x[:, :, self.rnn.hidden_size:]\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Example usage\n",
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "\n",
    "encoder = Encoder(vocab_size, units)\n",
    "\n",
    "input_tensor = next(iter(train_dataset))\n",
    "input_tensor = input_tensor[0].unsqueeze(0)\n",
    "output = encoder(input_tensor)\n",
    "print(output.shape)  # Expected shape: (32, 20, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "904c8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 256])\n"
     ]
    }
   ],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super(CrossAttention, self).__init__()\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim = units,  # the size of Q, K, V dims is the embedding dimension\n",
    "            num_heads = 1,  # Single head as in your Keras example\n",
    "            batch_first = True  # This ensures the input and output shapes are (batch_size, sequence_length, embedding_dim)\n",
    "        )\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(units)\n",
    "        self.add = nn.ModuleList([nn.Linear(units, units) for _ in range(2)])\n",
    "\n",
    "    def forward(self, context, target):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (torch.Tensor): Encoded sentence to translate\n",
    "            target (torch.Tensor): The embedded shifted-to-the-right translation\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Cross attention between context and target\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Call the MultiHeadAttention by passing in the query, key, and value\n",
    "        # For this case, the query should be the translation and the key/value the encoded sentence to translate\n",
    "        attn_output, _ = self.multihead_attn(query = target, key = context, value = context)\n",
    "        \n",
    "        x = self.add[0](target) + self.add[1](attn_output)\n",
    "        return self.layernorm(x)\n",
    "\n",
    "# Example usage\n",
    "units = config['UNITS']\n",
    "\n",
    "cross_attention = CrossAttention(units)\n",
    "\n",
    "# Assuming context and target tensors of shape (batch_size, seq_length, units)\n",
    "context_tensor = torch.randn(8, 16, units)  # Example tensor for context\n",
    "target_tensor = torch.randn(8, 16, units)    # Example tensor for target\n",
    "\n",
    "output = cross_attention(context_tensor, target_tensor)\n",
    "print(output.shape)  # Expected shape: (32, 8, units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "65c97ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 13000])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # The embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, units, padding_idx = 0)\n",
    "\n",
    "        # The RNN before attention\n",
    "        self.pre_attention_rnn = nn.LSTM(units, units, batch_first = True)\n",
    "\n",
    "        # The attention layer\n",
    "        self.attention = CrossAttention(units)\n",
    "\n",
    "        # The RNN after attention\n",
    "        self.post_attention_rnn = nn.LSTM(units, units, batch_first=True)\n",
    "\n",
    "        # The dense layer with logsoftmax activation\n",
    "        self.output_layer = nn.Linear(units, vocab_size)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, context, target, state=None, return_state=False):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (torch.Tensor): Encoded sentence to translate\n",
    "            target (torch.Tensor): The shifted-to-the-right translation\n",
    "            state (tuple(torch.Tensor, torch.Tensor), optional): Hidden state of the pre-attention LSTM. Defaults to None.\n",
    "            return_state (bool, optional): If set to true, return the hidden states of the LSTM. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The log_softmax probabilities of predicting a particular token\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Get the embedding of the input\n",
    "        x = self.embedding(target)\n",
    "        \n",
    "        # Pass the embedded input into the pre-attention LSTM\n",
    "        if state is None:\n",
    "            x, (hidden_state, cell_state) = self.pre_attention_rnn(x)\n",
    "        else:\n",
    "            x, (hidden_state, cell_state) = self.pre_attention_rnn(x, state)\n",
    "        \n",
    "        # Perform cross attention between the context and the output of the LSTM (in that order)\n",
    "        x = self.attention(context, x)\n",
    "\n",
    "        # Do a pass through the post-attention LSTM\n",
    "        x, _ = self.post_attention_rnn(x)\n",
    "\n",
    "        # Compute the logits\n",
    "        logits = self.output_layer(x)\n",
    "        \n",
    "        \n",
    "        # Apply log softmax\n",
    "        logits = F.log_softmax(logits, dim = -1)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        if return_state:\n",
    "            return logits, (hidden_state, cell_state)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# Example usage\n",
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "\n",
    "decoder = Decoder(vocab_size, units)\n",
    "\n",
    "# Assuming context and target tensors of shape (batch_size, seq_length)\n",
    "context_tensor = torch.randn(8, 15, units)  # Example tensor for context\n",
    "target_tensor = torch.randint(0, vocab_size, (8, 16)).long()  # Example tensor for target\n",
    "\n",
    "output = decoder(context_tensor, target_tensor)\n",
    "print(output.shape)  # Expected shape: (32, 8, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c2e34e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_Translator(nn.Module):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(NMT_Translator, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size, units)\n",
    "        self.decoder = Decoder(vocab_size, units)\n",
    "        \n",
    "    def forward(self, context, target):\n",
    "        encoded_context = self.encoder(context)\n",
    "        logits = self.decoder(encoded_context, target)\n",
    "        \n",
    "        return torch.argmax(logits, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "95b682ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 15]) torch.Size([8, 16])\n",
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "\n",
    "# Initialize the Translator model\n",
    "translator = NMT_Translator(vocab_size, units)\n",
    "\n",
    "# Example tensors\n",
    "context_tensor = torch.randint(0, vocab_size, (8, 15)).long()  # (batch_size, seq_len, units)\n",
    "target_tensor = torch.randint(0, vocab_size, (8, 16))  # (batch_size, seq_len)\n",
    "\n",
    "print(context_tensor.shape, target_tensor.shape)\n",
    "\n",
    "# Ensure the target tensor is Long type for embedding\n",
    "target_tensor = target_tensor.long()\n",
    "\n",
    "# Forward pass through the model\n",
    "output = translator(context_tensor, target_tensor)\n",
    "print(output.shape)  # Expected shape: (batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f55ccfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedLoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # CrossEntropyLoss expects y_true to be of shape (batch_size, seq_len)\n",
    "        y_pred = y_pred.argmax(dim=-1).float()\n",
    "        \n",
    "        mask = (y_true != 0).float()\n",
    "        y_pred *= mask\n",
    "        loss = self.loss_fn(y_pred, y_true.float())\n",
    "\n",
    "        # Create a mask where y_true is not padding (assuming 0 is the padding index)\n",
    "        mask = (y_true != 0).float()\n",
    "        \n",
    "\n",
    "        # Return the average loss\n",
    "        return loss.sum() / mask.sum()\n",
    "\n",
    "class MaskedAcc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedAcc, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Get the predicted class by taking argmax along the last dimension\n",
    "        y_pred = y_pred.argmax(dim=-1)\n",
    "\n",
    "        # Create a mask where y_true is not padding\n",
    "        mask = (y_true != 0).float()\n",
    "\n",
    "        # Compute the number of correct predictions\n",
    "        correct = (y_true == y_pred).float() * mask\n",
    "\n",
    "        # Return the accuracy\n",
    "        return correct.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ac8cd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, loss_fn, masked_loss_fn, masked_acc_fn, epochs=20, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            context, target_in, target_out = batch\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(context, target_in)\n",
    "            \n",
    "            \n",
    "            # Compute loss and accuracy\n",
    "            \n",
    "            loss = loss_fn(output.float(), target_out.float())\n",
    "            loss.requires_grad = True\n",
    "#             acc = masked_acc_fn(output, target_out)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "#             total_acc += acc.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "#         avg_acc = total_acc / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"Training loss: {avg_loss:.4f}, accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                context, target = batch\n",
    "                output = model(context, target)\n",
    "                loss = loss_fn(output.float(), target_out.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = config['MAX_VOCAB_SIZE']\n",
    "units = config['UNITS']\n",
    "model = NMT_Translator(vocab_size, units)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "masked_loss_fn = MaskedLoss()\n",
    "masked_acc_fn = MaskedAcc()\n",
    "\n",
    "trained_model = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn = loss, \n",
    "    masked_loss_fn=masked_loss_fn,\n",
    "    masked_acc_fn=masked_acc_fn,\n",
    "    epochs=20,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883350f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e09dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4df1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
