{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9147546,"sourceType":"datasetVersion","datasetId":5525416}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T15:34:41.408208Z","iopub.execute_input":"2024-08-11T15:34:41.408508Z","iopub.status.idle":"2024-08-11T15:34:42.267254Z","shell.execute_reply.started":"2024-08-11T15:34:41.408482Z","shell.execute_reply":"2024-08-11T15:34:42.266358Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/en-np-translation/train.ne\n/kaggle/input/en-np-translation/train.en\n","output_type":"stream"}]},{"cell_type":"code","source":"%%bash\npip install -q datasets sacrebleu torch transformers sentencepiece transformers[sentencepiece]\npip install -q accelerate -U\npip install -q wandb\npip install -q evaluate","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:34:42.269000Z","iopub.execute_input":"2024-08-11T15:34:42.269568Z","iopub.status.idle":"2024-08-11T15:35:30.123641Z","shell.execute_reply.started":"2024-08-11T15:34:42.269536Z","shell.execute_reply":"2024-08-11T15:35:30.122662Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport os\nimport numpy as np\nimport sacrebleu\nimport datasets\nimport warnings\nimport random\nimport re\nimport matplotlib.pyplot as plt\nimport evaluate\nimport wandb\n\nfrom tqdm import tqdm\nfrom collections import Counter\n\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset, load_metric\nfrom transformers import pipeline, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration, AutoModelForSeq2SeqLM\nfrom transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:36:53.555455Z","iopub.execute_input":"2024-08-11T15:36:53.556295Z","iopub.status.idle":"2024-08-11T15:36:53.575099Z","shell.execute_reply.started":"2024-08-11T15:36:53.556267Z","shell.execute_reply":"2024-08-11T15:36:53.574373Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"config = {\n    'EPOCHS': 10,\n    'BLEU': 'bleu',\n    'SRC_LANG_CODE': 'en',\n    'TGT_LANG_CODE': 'np',\n    'SRC_LANGUAGE': 'English',\n    'TGT_LANGUAGE': 'Nepali',\n    'SRC_TRAIN_RAW_PATH': '/kaggle/input/en-np-translation/train.en',\n    'TGT_TRAIN_RAW_PATH': '/kaggle/input/en-np-translation/train.ne',\n    'MAX_SEQ_LEN': 32,\n    'BATCH_SIZE': 32,\n    'DEVICE': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    'MODEL_ID': 't5-small',\n    'ENC_TYPE': 'utf-8',\n    'VOCAB_SIZE': 32000,\n    'MAX_SOURCE_LENGTH': 96,\n    'MAX_TARGET_LENGTH': 96,\n    'MAX_GEN_LENGTH': 128,\n    'WEIGHT_DECAY': 0.01,\n    'LR': 5e-5\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:37:33.015344Z","iopub.execute_input":"2024-08-11T15:37:33.015718Z","iopub.status.idle":"2024-08-11T15:37:33.021712Z","shell.execute_reply.started":"2024-08-11T15:37:33.015692Z","shell.execute_reply":"2024-08-11T15:37:33.020809Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with open(config['SRC_TRAIN_RAW_PATH'], 'r', encoding = config['ENC_TYPE']) as f:\n    en_lines = f.readlines()\n\nwith open(config['TGT_TRAIN_RAW_PATH'], 'r', encoding = config['ENC_TYPE']) as f:\n    ne_lines = f.readlines()\n\ndata_df = pd.DataFrame(list(zip(en_lines, ne_lines)), columns = [config['SRC_LANG_CODE'], config['TGT_LANG_CODE']])\ndata_df[config['SRC_LANG_CODE']] = data_df[config['SRC_LANG_CODE']].str.replace('\\n', '', regex = False)\ndata_df[config['TGT_LANG_CODE']] = data_df[config['TGT_LANG_CODE']].str.replace('\\n', '', regex = False)\n\ndel en_lines\ndel ne_lines\n\n# instruction fine-tuning\ndef generate_translate_prompt(row):\n    src_text = row[config['SRC_LANG_CODE']]\n    translate_prompt = f\"Translate the given sentence from {config['SRC_LANGUAGE']} to {config['TGT_LANGUAGE']}: \\\"{src_text}\\\"\"\n    return translate_prompt\n\ndata_df['input_prompt'] = data_df.apply(generate_translate_prompt, axis = 1)\n\ntrain_val_df, test_df = train_test_split(data_df, test_size = 0.05, random_state = 69)\ntrain_df, val_df = train_test_split(train_val_df, test_size = 0.15, random_state = 69)\n\n# huggingface dataset object\ntrain_ds_raw = Dataset.from_pandas(train_df, split = 'train')\nvalidation_ds_raw = Dataset.from_pandas(val_df, split = 'validation')\ntest_ds_raw = Dataset.from_pandas(test_df, split = 'test')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:37:16.320557Z","iopub.execute_input":"2024-08-11T15:37:16.320934Z","iopub.status.idle":"2024-08-11T15:37:19.251422Z","shell.execute_reply.started":"2024-08-11T15:37:16.320905Z","shell.execute_reply":"2024-08-11T15:37:19.250657Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config['MODEL_ID'])\nmodel = AutoModelForSeq2SeqLM.from_pretrained(config['MODEL_ID'])\nmodel.to(config['DEVICE'])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:37:58.155582Z","iopub.execute_input":"2024-08-11T15:37:58.155930Z","iopub.status.idle":"2024-08-11T15:38:01.901728Z","shell.execute_reply.started":"2024-08-11T15:37:58.155904Z","shell.execute_reply":"2024-08-11T15:38:01.900717Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d6b5701c594b27a368b97300df863b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92d64fe90fa43c1b33432f81212a1ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a5ec65415c442dba78a8a925a76ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e2ef23d34f4a2bad1324321e67ab3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27e22f1138d4458094a492d70ea76d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d3304eb7184064b664a72695947e55"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"t5_translation_prompt = 'translate English to Nepali:'\n\ndef tokenize_function(batch):\n    source_inputs = [f\"{t5_translation_prompt} {example}\" for example in batch['en']]\n    target_outputs = [example for example in batch['np']]\n    return tokenizer(source_inputs, text_target = target_outputs, max_length = 256, truncation = True, padding = 'max_length')\n\n# tokenize dataset in batch for speed\ntrain_dataset = train_ds_raw.map(tokenize_function, batched=True, remove_columns = ['en', 'np', 'input_prompt', '__index_level_0__'])\nvalidation_dataset = validation_ds_raw.map(tokenize_function, batched=True, remove_columns = ['en', 'np', 'input_prompt', '__index_level_0__'])\ntest_dataset = test_ds_raw.map(tokenize_function, batched=True, remove_columns = ['en', 'np', 'input_prompt', '__index_level_0__'])\n\ntrain_dataset, validation_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:38:17.138741Z","iopub.execute_input":"2024-08-11T15:38:17.139106Z","iopub.status.idle":"2024-08-11T15:39:02.306605Z","shell.execute_reply.started":"2024-08-11T15:38:17.139078Z","shell.execute_reply":"2024-08-11T15:39:02.305762Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/122689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f290119b646461e9d1ac24cb762f95a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21651 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8bd51a0e60f4f33bbf5dc9496a5fd99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7597 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002ceadbaff4413ca09daed88ac7af6d"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_ids', 'attention_mask', 'labels'],\n     num_rows: 122689\n }),\n Dataset({\n     features: ['input_ids', 'attention_mask', 'labels'],\n     num_rows: 21651\n }),\n Dataset({\n     features: ['input_ids', 'attention_mask', 'labels'],\n     num_rows: 7597\n }))"},"metadata":{}}]},{"cell_type":"code","source":"# import metric\nbleu_metric = evaluate.load('bleu')\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    \n    # decode predicted sentence and skip special tokens\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # add padding (-100 = invalid token) and decode predicted target labels\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # postprocess for bleu metric\n    post_decoded_preds = [pred.strip() for pred in decoded_preds]\n    post_decoded_labels = [[label.strip()] for label in decoded_labels]\n    \n    # compute blue score\n    result = bleu_metric.compute(predictions=post_decoded_preds, references=post_decoded_labels)\n    \n    return {'bleu': result['bleu']}","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:39:33.957370Z","iopub.execute_input":"2024-08-11T15:39:33.957755Z","iopub.status.idle":"2024-08-11T15:39:35.411959Z","shell.execute_reply.started":"2024-08-11T15:39:33.957726Z","shell.execute_reply":"2024-08-11T15:39:35.410790Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eceae632367941e2be49f42ceee5cd63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f7b9c22c3db4f4aa5eefe6343f0a3dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29fc4724a6a64666914910f1901dc07d"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer = tokenizer,\n    model = model,\n    pad_to_multiple_of = 8\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:39:39.393717Z","iopub.execute_input":"2024-08-11T15:39:39.394186Z","iopub.status.idle":"2024-08-11T15:39:39.399884Z","shell.execute_reply.started":"2024-08-11T15:39:39.394146Z","shell.execute_reply":"2024-08-11T15:39:39.398604Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = '/kaggle/working/fine-tuned-translation-en-np',\n    optim = 'adamw_torch',\n    num_train_epochs = 3,\n    per_device_train_batch_size = 32,\n    per_device_eval_batch_size = 32,\n    save_strategy = 'epoch',\n    evaluation_strategy = 'epoch',\n    load_best_model_at_end=True,\n    report_to = 'none',\n    fp16 = True,\n    predict_with_generate = True,\n)\n\n# we setup trainer with all previous variables\ntrainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset = validation_dataset,\n    tokenizer = tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:43:49.184900Z","iopub.execute_input":"2024-08-11T15:43:49.185282Z","iopub.status.idle":"2024-08-11T15:43:49.221799Z","shell.execute_reply.started":"2024-08-11T15:43:49.185253Z","shell.execute_reply":"2024-08-11T15:43:49.221015Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:39:51.309410Z","iopub.execute_input":"2024-08-11T15:39:51.310157Z","iopub.status.idle":"2024-08-11T15:42:59.262765Z","shell.execute_reply.started":"2024-08-11T15:39:51.310126Z","shell.execute_reply":"2024-08-11T15:42:59.261723Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [475/475 03:05]\n    </div>\n    "},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 11.13097858428955,\n 'eval_bleu': 0.007495560437934589,\n 'eval_runtime': 187.9439,\n 'eval_samples_per_second': 40.422,\n 'eval_steps_per_second': 2.527}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:43:51.645324Z","iopub.execute_input":"2024-08-11T15:43:51.645709Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9159' max='11505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9159/11505 1:55:50 < 29:40, 1.32 it/s, Epoch 2.39/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.028100</td>\n      <td>0.025754</td>\n      <td>0.031191</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.025600</td>\n      <td>0.024373</td>\n      <td>0.054622</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"FineTunedTransformer\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline('translation_en_to_ne', model=model.to('cpu'), tokenizer=tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"translate English to French: I like this machine learning notebook.\"\ntranslator(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}